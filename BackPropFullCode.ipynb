{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCs6JY8aLI_d"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRSO56VjLLM9"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def cross_entropy(y_pred, y_true):\n",
        "    return -(y_true @ np.log(y_pred))\n",
        "\n",
        "def d_cross_entropy(y, y_pred):\n",
        "    return -(y - y_pred)\n",
        "\n",
        "def softmax(L):\n",
        "    arr = []\n",
        "    for i in L:\n",
        "        arr.append(np.exp(i) / np.exp(L).sum())\n",
        "\n",
        "    return arr\n",
        "\n",
        "def dsigmoid(x):\n",
        "    return sigmoid(x) * sigmoid(1- x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx5cPJmFLOCK"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(inputs, hidden_layers, outputs):\n",
        "    parameters = {}\n",
        "    parameters[\"W1\"] = np.random.rand(hidden_layers[0], inputs)\n",
        "    parameters[\"b1\"] = np.random.rand(hidden_layers[0])\n",
        "    for i in range(1, len(hidden_layers)):\n",
        "        parameters[f\"W{i+1}\"] = np.random.rand(hidden_layers[i], hidden_layers[i - 1])\n",
        "        parameters[f\"b{i+1}\"] = np.random.rand(hidden_layers[i])\n",
        "    parameters[f\"W{len(hidden_layers) + 1}\"] = np.random.rand(outputs, hidden_layers[-1])\n",
        "    parameters[f\"b{len(hidden_layers) + 1}\"] = np.random.rand(outputs)\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rx9ZnMzLQc3",
        "outputId": "3b3628dc-ae9f-4a25-fccb-9429988c21cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'W1': array([[0.77598964, 0.11086056, 0.30225126],\n",
              "        [0.11365554, 0.26429342, 0.52373418],\n",
              "        [0.79322532, 0.64690812, 0.8974008 ]]),\n",
              " 'b1': array([0.36480097, 0.9341658 , 0.20235546]),\n",
              " 'W2': array([[0.14300462, 0.20842507, 0.36226225],\n",
              "        [0.45635101, 0.68723658, 0.36556873],\n",
              "        [0.30971569, 0.22668197, 0.01672032]]),\n",
              " 'b2': array([0.52674602, 0.14504988, 0.01473813]),\n",
              " 'W3': array([[0.53690854, 0.07699711, 0.46227208],\n",
              "        [0.16290924, 0.27618729, 0.22235894],\n",
              "        [0.65722696, 0.43030143, 0.54799411]]),\n",
              " 'b3': array([0.51138319, 0.89299058, 0.60671539])}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initialize_parameters(3, [3, 3], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkSTlAAxOq01"
      },
      "outputs": [],
      "source": [
        "W1 = np.array([\n",
        "    [0.5488135, 0.71518937, 0.60276338],\n",
        "    [0.54488318, 0.4236548, 0.64589411],\n",
        "    [0.43758721, 0.891773, 0.96366276]\n",
        "])\n",
        "W2 = np.array([\n",
        "    [0.56804456, 0.92559664, 0.07103606],\n",
        "    [0.0871293, 0.0202184, 0.83261985],\n",
        "    [0.77815675, 0.87001215, 0.97861834]\n",
        "])\n",
        "W3 = np.array([\n",
        "    [0.11827443, 0.63992102, 0.14335329],\n",
        "    [0.94466892, 0.52184832, 0.41466194],\n",
        "    [0.26455561, 0.77423369, 0.45615033]\n",
        "])\n",
        "\n",
        "b1 = np.array(\n",
        "    [0.38344152, 0.79172504, 0.52889492]\n",
        ")\n",
        "\n",
        "b2 = np.array(\n",
        "    [0.7991586, 0.46147936, 0.52889492]\n",
        ")\n",
        "\n",
        "b3 = np.array(\n",
        "    [0.56843395, 0.0187898, 0.6176355]\n",
        ")\n",
        "\n",
        "X = np.array(\n",
        "    [[1, 0, 1]]\n",
        ")\n",
        "\n",
        "Y = np.array(\n",
        "    [[0, 0, 1]]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMb9tv5oOmly"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'W1': W1,\n",
        "    'W2': W2,\n",
        "    'W3': W3,\n",
        "    'b1': b1,\n",
        "    'b2': b2,\n",
        "    'b3': b3,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaqCXQ6bMvGa"
      },
      "outputs": [],
      "source": [
        "def forward_propogation(parameters, x, g, O):\n",
        "    activations = {}\n",
        "    activations[\"a1\"] = parameters[\"W1\"] @ x + parameters[\"b1\"]\n",
        "    activations[\"h1\"] = g(activations[\"a1\"])\n",
        "    for i in range(2, len(parameters) // 2):\n",
        "        activations[f\"a{i}\"] = parameters[f\"W{i}\"] @ activations[f\"h{i - 1}\"] + parameters[f\"b{i}\"]\n",
        "        activations[f\"h{i}\"] = g(activations[f\"a{i}\"])\n",
        "\n",
        "    activations[f\"a{len(parameters) // 2}\"] = parameters[f\"W{len(parameters) // 2}\"] @ activations[f\"h{len(parameters) // 2 - 1}\"] + parameters[f\"b{len(parameters) // 2}\"]\n",
        "    y_pred = O(activations[f\"a{len(parameters) // 2}\"])\n",
        "    return y_pred, activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgwYnxZ_Ov6d",
        "outputId": "c22ba179-67dc-4a1a-d0e4-e9e95261f05c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([0.23756972385440864, 0.3381938464839215, 0.42423642966166986],\n",
              " {'a1': array([1.5350184 , 1.98250233, 1.93014489]),\n",
              "  'h1': array([0.82273938, 0.87894766, 0.87326546]),\n",
              "  'a2': array([2.14209557, 1.27803313, 2.78840386]),\n",
              "  'h2': array([0.89492782, 0.78211479, 0.94204596]),\n",
              "  'a3': array([1.30981811, 1.6629762 , 1.88964787])})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forward_propogation(parameters, x, sigmoid, softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08eIgLL1PZ7y"
      },
      "outputs": [],
      "source": [
        "def backPropogation(y_pred, y, activations, g_dash, O_dash, parameters, x):\n",
        "    losses = {}\n",
        "    n = len(parameters) // 2\n",
        "    m = len(activations) // 2\n",
        "    La = O_dash(y, y_pred)\n",
        "\n",
        "    Lh = La @ parameters[f\"W{n}\"]\n",
        "\n",
        "    da = g_dash(activations[f\"a{m}\"])\n",
        "    losses[f\"LW{n}\"] = np.outer(La, activations[f\"h{m}\"])\n",
        "    losses[f\"Lb{n}\"] = La.copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(1, m):\n",
        "        La = Lh * da\n",
        "        Lh = La @ parameters[f\"W{m - i + 1}\"]\n",
        "        da = g_dash(activations[f\"a{m - i}\"])\n",
        "        losses[f\"LW{m - i + 1}\"] = np.outer(La, activations[f\"h{m - i}\"])\n",
        "        losses[f\"Lb{m - i + 1}\"] = La.copy()\n",
        "\n",
        "    La = Lh * da\n",
        "    losses[\"LW1\"] = np.outer(La, x)\n",
        "    losses[\"Lb1\"] = La.copy()\n",
        "\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9J67lZeVk-t"
      },
      "outputs": [],
      "source": [
        "y_pred, activations = forward_propogation(parameters, x, sigmoid, softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLaUMtvAVhki"
      },
      "outputs": [],
      "source": [
        "gradient_loss = backPropogation(y_pred, y, activations, dsigmoid, d_cross_entropy, parameters, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkMw_Texbr3U"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(parameters, losses, eta):\n",
        "    new_parameters = {}\n",
        "    for i in range(len(parameters) // 2):\n",
        "        new_parameters[f\"W{i + 1}\"] = parameters[f\"W{i + 1}\"] - eta * losses[f\"LW{i + 1}\"]\n",
        "        new_parameters[f\"b{i + 1}\"] = parameters[f\"b{i + 1}\"] - eta * losses[f\"Lb{i + 1}\"]\n",
        "    return new_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8840v0QcOWb"
      },
      "outputs": [],
      "source": [
        "new_parameters = gradient_descent(parameters, gradient_loss, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN6xUPw7cmJR"
      },
      "outputs": [],
      "source": [
        "y_pred, activations = forward_propogation(new_parameters, x, sigmoid, softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTd_XfnYczZu",
        "outputId": "6e5bb56f-5cf3-4ee3-adf9-893a7477f119"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.07711344018879235"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_entropy(y_pred, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpOpK0FFe__l"
      },
      "source": [
        "# Backpropogation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag2iSrF_cmax"
      },
      "outputs": [],
      "source": [
        "from scipy.special import expit\n",
        "\n",
        "# Helper Functions\n",
        "def sigmoid(x):\n",
        "    return expit(x)\n",
        "\n",
        "def cross_entropy(y_pred, y_true, epsilon=1e-15):\n",
        "    # Clip y_pred to avoid values close to 0 or 1\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    return -(y_true @ np.log(y_pred))\n",
        "\n",
        "def d_cross_entropy(y, y_pred):\n",
        "    return -(y - y_pred)\n",
        "\n",
        "def softmax(L):\n",
        "    exp_L = np.exp(L - np.max(L))  # Subtract the maximum value to avoid overflow\n",
        "    return exp_L / exp_L.sum(axis=0, keepdims=True)  # Compute softmax along the specified axis\n",
        "\n",
        "def dsigmoid(x):\n",
        "    return sigmoid(x) * sigmoid(1- x)\n",
        "\n",
        "# Initialize Parameters\n",
        "\n",
        "def initialize_parameters(inputs, hidden_layers, outputs):\n",
        "    parameters = {}\n",
        "    parameters[\"W1\"] = np.random.rand(hidden_layers[0], inputs)\n",
        "    parameters[\"b1\"] = np.random.rand(hidden_layers[0])\n",
        "    for i in range(1, len(hidden_layers)):\n",
        "        parameters[f\"W{i+1}\"] = np.random.rand(hidden_layers[i], hidden_layers[i - 1])\n",
        "        parameters[f\"b{i+1}\"] = np.random.rand(hidden_layers[i])\n",
        "    parameters[f\"W{len(hidden_layers) + 1}\"] = np.random.rand(outputs, hidden_layers[-1])\n",
        "    parameters[f\"b{len(hidden_layers) + 1}\"] = np.random.rand(outputs)\n",
        "    return parameters\n",
        "\n",
        "# Forward Propogation\n",
        "\n",
        "def forward_propogation(parameters, x, g, O):\n",
        "    activations = {}\n",
        "\n",
        "    activations[\"a1\"] = parameters[\"W1\"] @ x + parameters[\"b1\"]\n",
        "    activations[\"h1\"] = g(activations[\"a1\"])\n",
        "    for i in range(2, len(parameters) // 2):\n",
        "        activations[f\"a{i}\"] = parameters[f\"W{i}\"] @ activations[f\"h{i - 1}\"] + parameters[f\"b{i}\"]\n",
        "        activations[f\"h{i}\"] = g(activations[f\"a{i}\"])\n",
        "\n",
        "    activations[f\"a{len(parameters) // 2}\"] = parameters[f\"W{len(parameters) // 2}\"] @ activations[f\"h{len(parameters) // 2 - 1}\"] + parameters[f\"b{len(parameters) // 2}\"]\n",
        "    y_pred = O(activations[f\"a{len(parameters) // 2}\"])\n",
        "    return y_pred, activations\n",
        "\n",
        "# Backpropogation\n",
        "\n",
        "def backPropogation(y_pred, y, activations, g_dash, O_dash, parameters, x):\n",
        "    losses = {}\n",
        "    n = len(parameters) // 2\n",
        "    m = len(activations) // 2\n",
        "    La = O_dash(y, y_pred)\n",
        "\n",
        "\n",
        "    Lh = La @ parameters[f\"W{n}\"]\n",
        "\n",
        "    da = g_dash(activations[f\"a{m}\"])\n",
        "    losses[f\"W{n}\"] = np.outer(La, activations[f\"h{m}\"])\n",
        "    losses[f\"b{n}\"] = La.copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(1, m):\n",
        "        La = Lh * da\n",
        "        Lh = La @ parameters[f\"W{m - i + 1}\"]\n",
        "        da = g_dash(activations[f\"a{m - i}\"])\n",
        "        losses[f\"W{m - i + 1}\"] = np.outer(La, activations[f\"h{m - i}\"])\n",
        "        losses[f\"b{m - i + 1}\"] = La.copy()\n",
        "\n",
        "    La = Lh * da\n",
        "    losses[\"W1\"] = np.outer(La, x)\n",
        "    losses[\"b1\"] = La.copy()\n",
        "\n",
        "\n",
        "    return losses\n",
        "\n",
        "# Gradient Descent (Batch)\n",
        "def gradient_descent(parameters, losses, eta):\n",
        "    for i in range(len(parameters) // 2):\n",
        "        parameters[f\"W{i + 1}\"] = parameters[f\"W{i + 1}\"] - eta * losses[f\"W{i + 1}\"]\n",
        "        parameters[f\"b{i + 1}\"] = parameters[f\"b{i + 1}\"] - eta * losses[f\"b{i + 1}\"]\n",
        "    return parameters\n",
        "\n",
        "def sgd(parameters, losses, eta):\n",
        "    new_parameters = {}\n",
        "    num_samples = len(losses)  # Number of data points or samples\n",
        "\n",
        "    # Iterate over each sample and update parameters using its corresponding gradient\n",
        "    for i in range(num_samples):\n",
        "        for j in range(1, len(parameters) // 2 + 1):  # Iterate over layers\n",
        "            new_parameters[f\"W{j}\"] = parameters[f\"W{j}\"] - eta * losses[f\"W{j}\"]\n",
        "            new_parameters[f\"b{j}\"] = parameters[f\"b{j}\"] - eta * losses[f\"b{j}\"]\n",
        "\n",
        "    return new_parameters\n",
        "\n",
        "\n",
        "def train(X, Y, epochs, hidden_layers, g, O, g_dash, O_dash, eta, optimizer):\n",
        "    parameters = initialize_parameters(X[0].shape[0], hidden_layers, Y[0].shape[0])\n",
        "    print(parameters)\n",
        "    for _ in range(epochs):\n",
        "        total_gradient_loss = {key: 0 for key in parameters.keys()}  # Initialize total gradient loss\n",
        "        for x, y in zip(X, Y):  # Iterate over each data point\n",
        "            y_pred, activations = forward_propogation(parameters, x, g, O)\n",
        "            gradient_loss = backPropogation(y_pred, y, activations, g_dash, O_dash, parameters, x)\n",
        "            # Accumulate the gradients for each data point\n",
        "            for key in total_gradient_loss:\n",
        "                total_gradient_loss[key] += gradient_loss.get(key, 0)\n",
        "        # Update the parameters using the accumulated gradients\n",
        "        parameters = optimizer(parameters, total_gradient_loss, eta)\n",
        "    return parameters\n",
        "\n",
        "def evaluate(X, parameters, g, O):\n",
        "    return np.array(forward_propogation(parameters, X, g, O)[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRZpWnjpc9jS",
        "outputId": "5fc01ff8-880a-4e48-9b49-f7819052ce55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'W1': array([[0.87587277, 0.92672285, 0.87456226, 0.17584757, 0.91949464,\n",
            "        0.52739797, 0.47525497, 0.74970912, 0.16905386, 0.61531109],\n",
            "       [0.66824326, 0.57244168, 0.97480688, 0.43733053, 0.11519756,\n",
            "        0.23291893, 0.03509665, 0.84786526, 0.24456808, 0.32763348],\n",
            "       [0.21250549, 0.27237536, 0.01871629, 0.74984428, 0.37838721,\n",
            "        0.4894164 , 0.3338544 , 0.30595014, 0.32448785, 0.49691844]]), 'b1': array([0.47253296, 0.03716997, 0.97390171]), 'W2': array([[0.8867403 , 0.56835411, 0.42025399],\n",
            "       [0.89992407, 0.22984957, 0.4143102 ],\n",
            "       [0.56335832, 0.52052592, 0.12128385],\n",
            "       [0.68321713, 0.1038356 , 0.45412441]]), 'b2': array([0.48048849, 0.13035009, 0.37971717, 0.4911684 ]), 'W3': array([[0.99960946, 0.20740405, 0.81982168, 0.4717515 ],\n",
            "       [0.18671358, 0.59537892, 0.13991907, 0.0122807 ],\n",
            "       [0.47032275, 0.37878221, 0.8311686 , 0.18291506],\n",
            "       [0.60849864, 0.65290657, 0.18513642, 0.85609373],\n",
            "       [0.37067216, 0.70792865, 0.56724982, 0.51616089]]), 'b3': array([0.19451435, 0.38387425, 0.30625388, 0.85498621, 0.13685802]), 'W4': array([[0.31884011, 0.74256658, 0.73398391, 0.54345265, 0.43688923],\n",
            "       [0.88258466, 0.96689705, 0.37557067, 0.18907122, 0.24974813],\n",
            "       [0.73355826, 0.03796224, 0.12087648, 0.33143067, 0.58250407]]), 'b4': array([0.56400654, 0.7840343 , 0.48185952])}\n"
          ]
        }
      ],
      "source": [
        "parameters = train(X, Y, 300, [3, 4, 5], sigmoid, softmax, dsigmoid, d_cross_entropy, 50, sgd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXRCUZao6S1b"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(inputs, hidden_layers, outputs):\n",
        "    parameters = {}\n",
        "    parameters[\"W1\"] = np.random.rand(hidden_layers[0], inputs)\n",
        "    parameters[\"b1\"] = np.random.rand(hidden_layers[0])\n",
        "    for i in range(1, len(hidden_layers)):\n",
        "        parameters[f\"W{i+1}\"] = np.random.rand(hidden_layers[i], hidden_layers[i - 1])\n",
        "        parameters[f\"b{i+1}\"] = np.random.rand(hidden_layers[i])\n",
        "    parameters[f\"W{len(hidden_layers) + 1}\"] = np.random.rand(outputs, hidden_layers[-1])\n",
        "    parameters[f\"b{len(hidden_layers) + 1}\"] = np.random.rand(outputs)\n",
        "\n",
        "    # Initialize AdaM parameters\n",
        "    v = {}\n",
        "    s = {}\n",
        "    for key in parameters.keys():\n",
        "        if key.startswith(\"W\") or key.startswith(\"b\"):\n",
        "            v[key] = np.zeros_like(parameters[key])\n",
        "            s[key] = np.zeros_like(parameters[key])\n",
        "\n",
        "    return parameters, v, s\n",
        "\n",
        "def adam(parameters, v, s, losses, eta, beta1=0.9, beta2=0.999, epsilon=1e-8, t=0):\n",
        "    for key in parameters.keys():\n",
        "        if key.startswith(\"W\") or key.startswith(\"b\"):\n",
        "            # Compute gradients\n",
        "            gradient = losses[key]\n",
        "\n",
        "            # Update time step\n",
        "            t += 1\n",
        "\n",
        "            # Update biased first moment estimate\n",
        "            v[key] = beta1 * v[key] + (1 - beta1) * gradient\n",
        "            # Update biased second moment estimate\n",
        "            s[key] = beta2 * s[key] + (1 - beta2) * (gradient ** 2)\n",
        "\n",
        "            # Correct the bias in the first moment\n",
        "            v_corrected = v[key] / (1 - beta1 ** t)\n",
        "            # Correct the bias in the second moment\n",
        "            s_corrected = s[key] / (1 - beta2 ** t)\n",
        "\n",
        "            # Update parameters\n",
        "            parameters[key] -= eta * v_corrected / (np.sqrt(s_corrected) + epsilon)\n",
        "\n",
        "    return parameters, v, s\n",
        "\n",
        "def train(X, Y, epochs, hidden_layers, g, O, g_dash, O_dash, eta, optimizer):\n",
        "    parameters, v, s = initialize_parameters(X[0].shape[0], hidden_layers, Y[0].shape[0])\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for x, y in zip(X, Y):\n",
        "            y_pred, activations = forward_propogation(parameters, x, g, O)\n",
        "            gradient_loss = backPropogation(y_pred, y, activations, g_dash, O_dash, parameters, x)\n",
        "            parameters, v, s = optimizer(parameters, v, s, gradient_loss, eta)\n",
        "\n",
        "    return parameters\n",
        "\n",
        "# Usage example:\n",
        "# parameters = train(X, Y, epochs, hidden_layers, sigmoid, softmax, dsigmoid, d_cross_entropy, eta, adam)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVsGnCB2oHrQ"
      },
      "outputs": [],
      "source": [
        "parameters = train(X, Y, 300, [3, 4, 5], sigmoid, softmax, dsigmoid, d_cross_entropy, 50, adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AG3AXQk6475",
        "outputId": "0c011f3e-e761-4190-e95f-e604a5e16312"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'W1': array([[-5.02209439e+02,  4.16844333e-01, -5.01526904e+02],\n",
              "        [-5.01715984e+02,  8.64809399e-01, -5.01972101e+02],\n",
              "        [-5.01292146e+02,  2.23744046e-01, -5.01413702e+02]]),\n",
              " 'b1': array([-373.12904845, -373.29534843, -372.92794635]),\n",
              " 'W2': array([[-320.74688975, -320.29730294, -320.4841101 ],\n",
              "        [-320.44501204, -320.837123  , -320.41702322],\n",
              "        [-320.48737929, -320.38157605, -320.21901062],\n",
              "        [ 321.11588654,  320.99456354,  321.40881369]]),\n",
              " 'b2': array([-290.97458564, -291.54261196, -291.54392323,  292.66516015]),\n",
              " 'W3': array([[ 274.13441419,  274.1853554 ,  274.15825997,  274.60886359],\n",
              "        [-273.69203896, -273.63974896, -273.86688601, -273.88255217],\n",
              "        [ 274.44111331,  274.73704266,  274.47631749,  274.19662018],\n",
              "        [-273.80691887, -273.83440881, -273.10587649, -273.74579177],\n",
              "        [-273.32720278, -273.34693567, -273.58828681, -273.8477254 ]]),\n",
              " 'b3': array([ 263.04495981, -262.08388004,  263.01919125, -261.39810496,\n",
              "        -262.02249706]),\n",
              " 'W4': array([[-254.28089842, -253.43438741, -253.96628064, -253.38539686,\n",
              "         -253.37179106],\n",
              "        [-253.51846437, -254.1875386 , -253.77656709, -253.98403924,\n",
              "         -254.21314575],\n",
              "        [ 255.06938533,  255.02344006,  255.13231104,  254.70591821,\n",
              "          254.78043591]]),\n",
              " 'b4': array([-248.02112184, -248.72577131,  249.42058164])}"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN91cC74nKVX",
        "outputId": "5e4681e4-c67d-45e1-dfc1-1de71b7b9a64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3,), (3,))"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0].shape, Y[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7OlYQ_heidr"
      },
      "outputs": [],
      "source": [
        "Y_pred = []\n",
        "for x in X:\n",
        "    y_pred = list(evaluate(x, parameters, sigmoid, softmax))\n",
        "    Y_pred.append(y_pred)\n",
        "Y_pred = np.array(Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2DJnDXce6x9",
        "outputId": "04813a0c-f115-4c08-d462-05bab7a7d3ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0, 0, 1]]), array([[0., 0., 1.]]))"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y, Y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUvZUBc5fyFy"
      },
      "source": [
        "# Testing phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDLEVE7Uf0cy",
        "outputId": "b1799b40-c53e-4d5e-e1af-5bd019185d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (10, 10)\n",
            "Original y: [1 0 1 0 1 0 1 0 1 0]\n",
            "One-hot encoded y:\n",
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Original data\n",
        "# y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n",
        "\n",
        "# # Create X such that the index of the number of y is maximum in X\n",
        "# X = np.zeros((len(y), 10))  # Initialize X with zeros\n",
        "\n",
        "# beta = 0.85\n",
        "# for i in range(len(y)):\n",
        "#     max_index = y[i]  # Index of the number in y\n",
        "#     X[i, max_index] = beta  # Set the highest value in X\n",
        "#     X[i] += (1 - beta) / 9 # Add a small value to all elements to make sure they are not zero\n",
        "\n",
        "# print(\"X:\")\n",
        "# print(X)\n",
        "# print(\"Shape of X:\", X.shape)\n",
        "# print(\"y:\", y)\n",
        "# num_classes = 10\n",
        "# y_one_hot = np.eye(num_classes)[y]\n",
        "# y_one_hot\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([\n",
        "    [0.1, 0.5, 0.2, 0.9, 0.3, 0.6, 0.4, 0.8, 0.7, 0.2],\n",
        "    [0.3, 0.2, 0.7, 0.4, 0.6, 0.8, 0.9, 0.5, 0.1, 0.3],\n",
        "    [0.8, 0.9, 0.4, 0.1, 0.5, 0.2, 0.7, 0.6, 0.3, 0.9],\n",
        "    [0.6, 0.2, 0.3, 0.7, 0.4, 0.1, 0.8, 0.9, 0.5, 0.6],\n",
        "    [0.5, 0.1, 0.8, 0.2, 0.9, 0.7, 0.3, 0.4, 0.6, 0.5],\n",
        "    [0.7, 0.3, 0.6, 0.5, 0.8, 0.4, 0.1, 0.2, 0.9, 0.7],\n",
        "    [0.2, 0.8, 0.1, 0.6, 0.4, 0.5, 0.7, 0.3, 0.2, 0.8],\n",
        "    [0.9, 0.6, 0.5, 0.3, 0.7, 0.2, 0.4, 0.1, 0.8, 0.6],\n",
        "    [0.4, 0.7, 0.9, 0.8, 0.2, 0.3, 0.6, 0.5, 0.1, 0.4],\n",
        "    [0.5, 0.3, 0.7, 0.4, 0.1, 0.8, 0.2, 0.6, 0.7, 0.5]\n",
        "])\n",
        "\n",
        "y = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Original y:\", y)\n",
        "\n",
        "# Convert y to one-hot encoded vectors\n",
        "num_classes = len(np.unique(y))\n",
        "y_one_hot = np.eye(num_classes)[y]\n",
        "\n",
        "print(\"One-hot encoded y:\")\n",
        "print(y_one_hot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JGt69TcqWjf"
      },
      "outputs": [],
      "source": [
        "parameters = train(X, y_one_hot, 3000, [10], sigmoid, softmax, dsigmoid, d_cross_entropy, 0.01, adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJEnY0jSgW1b",
        "outputId": "75b2dac0-0d3e-41e7-c017-44aabe4bfb6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'W1': array([[ -2.51072087,   6.19766604,   0.67532679,  -0.99178004,\n",
              "           4.26468957,  -1.61609701,  -5.57679556,   1.00271536,\n",
              "           1.64213245,   1.07632908],\n",
              "        [ -2.44288028,  -3.39721088,   2.04884379,  -7.6637196 ,\n",
              "           4.30587898,   1.2795474 ,  -4.59169589,   1.53730854,\n",
              "          -0.14477385,  -0.09671343],\n",
              "        [ -5.68646646,   2.71630869,   1.48319004,  -2.61143038,\n",
              "           5.52352841,   2.18021446,   4.77360728,   2.98010979,\n",
              "          -4.7730624 ,  -2.89451556],\n",
              "        [ -2.43524232,  -3.18139909,   1.45336449,  -7.33256972,\n",
              "           4.26204423,   1.40242954,  -4.66638533,   1.52323293,\n",
              "          -0.25857428,  -0.06945312],\n",
              "        [ -5.72020058,   3.42649823,   1.68299755,  -2.60292743,\n",
              "           5.22512958,   3.04507946,   3.69233077,   2.52104526,\n",
              "          -5.11112125,  -2.54772547],\n",
              "        [ -2.62817088,  -3.05082959,   1.91350118,  -7.32940427,\n",
              "           4.36178001,   0.64396745,  -4.49615928,   2.00979363,\n",
              "          -0.1294903 ,  -0.10844144],\n",
              "        [  5.12653362, -13.13274768,   3.12946753,  -2.97059151,\n",
              "           3.46644513,   3.43431984,   1.81993391,  -1.72915674,\n",
              "           2.88185112,  -0.16684408],\n",
              "        [  4.83354275, -12.22381946,   3.00692452,  -2.90834923,\n",
              "           2.7436232 ,   3.38385534,   2.36522744,  -1.94711017,\n",
              "           3.20573499,  -0.20580212],\n",
              "        [  4.77303745, -12.68035893,   3.07859246,  -2.83814183,\n",
              "           2.93390548,   3.18661049,   2.13494667,  -2.05296036,\n",
              "           3.0575825 ,  -0.04463465],\n",
              "        [  5.24835014, -13.74379764,   3.39955386,  -3.05414761,\n",
              "           3.30054766,   3.35264052,   2.02391156,  -1.74037215,\n",
              "           3.15129251,  -0.04007403]]),\n",
              " 'b1': array([0.37679624, 0.15501174, 0.85864855, 0.47304945, 0.74655668,\n",
              "        0.33126129, 0.54058014, 0.26028086, 0.63582291, 0.49420149]),\n",
              " 'W2': array([[-2.53770423, -3.41020128, -2.28586382, -3.52187379, -1.94746565,\n",
              "         -3.80202652,  3.72193544,  3.6819045 ,  3.50036993,  3.6503617 ],\n",
              "        [ 4.01035383,  4.1969938 ,  2.69647668,  4.42692749,  2.7634962 ,\n",
              "          3.99447626, -2.29317184, -2.64380813, -2.42940192, -2.31167587]]),\n",
              " 'b2': array([0.95552614, 0.44991346])}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJtYlqEsqct7"
      },
      "outputs": [],
      "source": [
        "Y_pred = []\n",
        "for x in X:\n",
        "    y_pred = list(evaluate(x, parameters, sigmoid, softmax))\n",
        "    Y_pred.append(y_pred)\n",
        "Y_pred = np.array(Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXn67QtrqptM",
        "outputId": "fe4d499c-ba46-4008-f5fd-d259ebe12de1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[1.06046168e-06, 9.99998940e-01],\n",
              "        [9.99996379e-01, 3.62106986e-06],\n",
              "        [7.16625520e-07, 9.99999283e-01],\n",
              "        [9.99999647e-01, 3.52673575e-07],\n",
              "        [3.49575888e-06, 9.99996504e-01],\n",
              "        [9.99998245e-01, 1.75539432e-06],\n",
              "        [2.44181581e-07, 9.99999756e-01],\n",
              "        [9.99999870e-01, 1.29693404e-07],\n",
              "        [7.91537154e-07, 9.99999208e-01],\n",
              "        [9.99999282e-01, 7.17695289e-07]]),\n",
              " array([[0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.]]))"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_pred, y_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHx8bbtKrwWb",
        "outputId": "7a04b372-5cc7-4fc7-a75b-10b624b1eaa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "for i in Y_pred:\n",
        "    print(i.argmax())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
